\documentclass[12pt,letterpaper,twoside]{article}
\usepackage{cme211}

\usepackage{atbegshi}% http://ctan.org/pkg/atbegshi
\AtBeginDocument{\AtBeginShipoutNext{\AtBeginShipoutDiscard}}

\begin{document}
\title{Lecture 7: Data Representation, Numerical Python\vspace{-5ex}}
\date{October 16th, 2018}
\maketitle

{\footnotesize
\paragraph{Topics Introduced:} Binary vs. Decimal systems, simplified
concepts of computer architecture including hierarchical memory and
arithmetic logic units, representation of integers, strings, and
floating point types, as well as \texttt{numpy}.
}
\vspace{-3ex}
\section{Representation of Data}

\subsection{Computer Representation of Integers}
Computers represent and store everything in
\href{https://en.wikipedia.org/wiki/Binary_number#Binary_counting}{\emph{binary}},
which is a base 2 number system. How is this different from what we
are familiar with in our base-10 (i.e. decimal) number system?

\begin{itemize}
\item Decimal counting uses the symbols 0-9.
\item Counting starts by incrementing the least-significant
  (rightmost) digit.

\begin{verbatim}
000, 001, 002, ..., 009
\end{verbatim}
\item When we exhaust the set of available symbols, we realize a type
  of overflow, in which the least-significant digit is reset to zero
  and the next digit of higher significance is incremented.

\begin{verbatim}
010, 011, 012, ..., 099
\end{verbatim}

\item We repeat this process of allowing for overflow with each digit
  of significance.

\begin{verbatim}
100, 101, 102, ...  
\end{verbatim}
\end{itemize}

To be formal, you can think of the integer $d_m
d_{m-1} \ldots d_1 d_0$ as being equivalent shorthand for
\[
  d_0 \times 10^0 + d_1 \times 10^1 + \ldots + d_{m-1} \times 10^{m-1}
  + d_m \times 10^m,
\]

where each symbol $d_i$ can take on a single value from the set $\{0,
1, \ldots, 9\}$.
\href{https://en.wikipedia.org/wiki/Binary_number#Binary_counting}{Counting
  in binary} is no different, sparing the fact that our set of
symbols is reduced to have cardinality two, i.e. the atomic elements are
\href{https://en.wikipedia.org/wiki/Bit}{\emph{binary digits} (bits)}
which can be toggled between zero or one.

\begin{centering}
\begin{table}[h]
  \hspace{-6ex}
\begin{tabular}{l r r r r r r r r r r r r r r r r}
  Decimal & 0 & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10 & 11 & 12 & 13
  & 14 & 15 \\
  Binary & 0 & 1 & 10 & 11 & 100 & 101 & 110 & 111 & 1000 & 1001 &
                                                                   1010
                                                       & 1011 & 1100 &
                                                                       1101
  & 1110 & 1111
\end{tabular}
\caption{A table describing how values can be equivalently represented
  in either a decimal or a
  binary number system.}
\end{table}
\end{centering}

To be formal, we can think of the integer $b_m b_{m-1} \ldots b_1 b_0$
as being equivalent shorthand for
\[
  b_0 \times 2^0 + b_1 \times 2^2 + \ldots + b_{m-1} \times 2^{m-1} +
  b_m \times 2^m
\]
where here we are using $b_i$'s to remind ourselves that each symbol
is a binary digit taking on only one of two values. Notice that other
than the set of symbols changing, the \emph{base} has changed as well,
from 10 to 2. Once you learn these basics, \href{https://en.wikipedia.org/wiki/Binary_number#Conversion_to_and_from_other_numeral_systems}{converting between numeral
systems} is easy.

There are 8 bits in a
\href{https://en.wikipedia.org/wiki/Byte}{byte}. Depending on the
computer architecture, a
\href{https://en.wikipedia.org/wiki/Word_(computer_architecture)}{word}
could be 4 or 8 bytes.

\subsubsection{Simplified Model of Computer}
Where are our data stored on a computer? How is it operated on?
A typical computer will have a memory hierarchy to facilitate
long-term storage (e.g. hard-disk), medium-term storage (RAM), and
short-term storage (cache). We present a simplified computer
architecture below, which does not picture long-term storage.

\begin{figure}[h]
\centering
\includegraphics[scale=0.45]{fig/model-computer.png}
\caption{\footnotesize We take a simplified view of a computer architecture. In
  particular, we show the relationship between
  \href{https://en.wikipedia.org/wiki/Computer_data_storage\#Primary_storage}{primary
    memory}
  (e.g. \href{https://en.wikipedia.org/wiki/Random-access_memory}{RAM})
  and a
  \href{https://en.wikipedia.org/wiki/Central_processing_unit}{CPU}. The
  CPU contains (i)
  \href{https://en.wikipedia.org/wiki/Arithmetic_logic_unit\#Functions}{arithmetic
    logic units} which take two inputs and produce a single output
  (think of the operators \texttt{+}, \texttt{-}, \texttt{\&}, and \texttt{|}) and (ii)
  \href{https://en.wikipedia.org/wiki/Processor_register}{registers}
  which can (very quickly) store inputs for ALU operations and hold corresponding outputs.}
\end{figure}

\subsubsection{Common Prefixes}
There can be some confusion here depending on the context of
usage. That is, in the context of networking and storage, the prefixes
\texttt{kilo}, \texttt{mega}, \texttt{giga}, \texttt{tera},
\texttt{peta}, and \texttt{exa} all use base 2. However, many other
contexts speak in base 10, e.g. cpu-frequencies and ethernet speeds.

The prefix
\href{https://en.wikipedia.org/wiki/Kilobyte#Definitions_and_usage}{kilo}
always means one-thousand in the prefix of an
\href{https://en.wikipedia.org/wiki/International_System_of_Units#Prefixes}{International
  System of Units}. However, since we understand the difference
between a \texttt{bit} and a \texttt{byte}, we can now understand that
there is a difference between a \texttt{kilobyte} (denoted by \textbf{kB}) and
a \emph{kibibyte} (denoted by \textbf{KiB}). The former is 1,000 bytes, i.e. 8,000
bits, whereas the latter is 1,024 bytes. i.e. 8,192 bytes.
We ask that you remember that there is a big difference between these
terms, but not necessarily that you remember the exact terminology or
symbols used to denote each. Wikipedia has a nice table demonstrating
how binary and decimal systems use
\href{https://en.wikipedia.org/wiki/Orders_of_magnitude_(data)}{different prefixes across orders of magnitude}. 

\subsubsection{Computer Storage of an Integer}
At the hardware level computers \textbf{don't} do variable length
representations of numbers. I.e. although we may use a variable length
representation, writing $4_{10} = 100_2$, or $73_{10} = 1001001_2$,
computers often use a fixed width storage for numeric types.

\begin{figure}
\centering
\includegraphics[scale=0.35]{fig/bits.png}
\caption{\footnotesize We can think of a (fixed-width) sequence of bits as a panel
  of lightswitches, each capable of being toggled on or off. }
\end{figure}

At the hardware level computers typically handle integers using 8, 16,
32, or 64 bits, depending on the architecture.

\vspace{-3ex}
\paragraph{Number of Representable Values Given $n$ Bits}
Realize that for a sequence of \texttt{n} bits, it may take on exactly
$2^n$ different values.
This dictates the range of what can be represented with a fixed number
of bits. Some common bounds we run into are.
\begin{verbatim}
2^8  = 256
2^16 = 65536                   ~(65 thousand)
2^32 = 4294967296              ~(4 billion)
2^64 = 18446744073709551616    ~(18 followed by 18 zeros)
\end{verbatim}

I.e. when we went from 32-bit machines to 64-bit machines, we didn't
just double their capacity. The latter can store
10 orders of magnitude more information (in each register), akin to allowing 10
more decimal digits to be represented. This follows from the fact that

$$
\log_{10}(2^{64} / 2^{32}) = 64 \log_{10}(2) - 32 \log_{10}(2) = 32
\log_{10}(2) \approx 10.
$$

\vspace{-3ex}
\paragraph{Using a Sign Bit to Store Negative Integers}
The idea is to simply use one bit to store the sign of a value, and
the remaining bits to track magnitude.
This reduces the range of the magnitude from $2^n$ to
$2^{n-1}$. E.g. suppose that we have a
\href{https://en.wikipedia.org/wiki/Nibble}{nibble} to work with,
i.e. four bits. We can represent the values
$\pm 4$ as indicated at the right of each statement.

\begin{align*}
  \texttt{4}_{10} &= \hspace{30pt} (\texttt{100})_2 &&\leadsto (\texttt{0100}) \\
  -\texttt{4}_{10} &= -1 \times (\texttt{100})_2 &&\leadsto (\texttt{1100})
\end{align*}

\paragraph{Offset: An Unconventional Way to Represent Negative Values}
Another idea instead of using a sign bit is to simply
apply an offset or bias to reinterpret the conversion between binary
and decimal. One example may look as follows.

\begin{figure}[h]
\centering
\includegraphics[scale=0.5]{fig/sign-offset.png}
\caption{\footnotesize Suppose we have a byte or eight bits. There are $2^8
= 256$ values that can be represented by such a sequence of
bits. Centering the number of distinct values around the integer zero,
we find that we can represent the set of values $\{-127, \ldots, 0, 1,
\ldots, 128\}$. If we use an offset method for representing integers,
then we may decide to set the sequence of eight bits as all zero's to
represent the minimum value $-127$, and from here we can apply the
usual rules of carry-over/overflow to count our way up to $128$.}
\end{figure}

Again, whether we use the idiom of a sign-bit or if we apply an
offset, either way we effectively reduce the range of the magnitude of
integers allowed. Intuitively, whether or not a number is positive or
negative should \emph{require one unit of information}.

Many programming languages support unsigned integers. Although
Python itself does not have \textbf{unsigned integers}, but \texttt{numpy} does.
A programmer can use this to their advantage by expanding the effective range available
if negative numbers don't need to be stored.
But! With any fixed-storage representage of a real number, we must beware.

\begin{itemize}
\item Attempting to assign a value greater than what can be represented by
the data type will result in \href{https://en.wikipedia.org/wiki/Integer_overflow}{\emph{overflow}}.
Overflow tends to cause \emph{wraparound}, e.g.~if adding
together two signed numbers causes overflow the result is likely to be
a negative number.

\item Attempting to assigning a value less than what can be represented by
the data type will result in
\href{https://en.wikipedia.org/wiki/Arithmetic_underflow}{\emph{underflow}}.\footnote{We
  can try to fill the underflow gap using \href{https://en.wikipedia.org/wiki/Denormal_number}{denormal numbers}.}
  Underflow can cause a division by zero error, for example, if we
  were to scale by the difference between two quantities
  $\frac{1}{b-a}$ where $a \neq b$ but $a \approx b$. 
\end{itemize}

\subsubsection{Range of Integer Types}
For a fixed number of bits, if we choose to represent sequential
integers centered around zero we must make a decision on boundaries.
E.g. with eight bits, one can store
$2^8 = 256$ unique different bit-sequences (or values), where we have the choice of
either being able to represent the values $\{-128, \ldots, 127\}$ or
$\{-127, \ldots, 128\}$. In general, an $n$-bit representation of an
integer stores the values in the set
\[
  \{\underbrace{-2^{n-1}, \ldots, -1}_{2^{n-1} \textrm{ elements}}, \underbrace{0,
  \ldots, 2^{n-1} - 1}_{2^{n-1} \textrm{ elements}}\}.
\]

\paragraph{Integers in Python}

In Python 3, values of type \texttt{int} may have unlimited
range.\footnote{Python 2 had both fixed size integers (with type \texttt{int}) and
  variable width integers (with type \texttt{long}).}
This is quite nice, and perhaps surprising if you come from
other programming languages.

\begin{python}[basicstyle=\small]
i = 52**100
print(type(i))   # <class 'int'>
print(i)         # This is beyond the 64-bit integer range.
\end{python}

The module \texttt{numpy} supports \emph{only} fixed-width integers
for reasons that relate to both performance and storage.

\subsection{Strings}

\subsubsection{ASCII}
American Standard Code for Information Interchange (ASCII) is
typically used to encode text information.
Characters, numbers, symbols, etc. are encoded using 7 bits (although
on modern computers they would typically use 8 bits).

E.g. \texttt{A} maps to $\texttt{(1000001)}_2 = (65)_{10}$,
and \texttt{B} maps to $\texttt{(1000010)}_2 = (66)_{10}$.

Default Python 2 string is ASCII. Possible to get \href{https://en.wikipedia.org/wiki/Unicode}{Unicode} strings with \newline
\texttt{s\ =\ u\textquotesingle{}I\ am\ a\ unicode\
  string!\textquotesingle{}}.

\subsubsection{Why Not ASCII All The Way Down? Motivating UTF-8}
\paragraph{For English, A Single Byte Suffices}
The English language has
26 letters (52 if we include casing). If we throw in punctuation and
digits 0-9, we realize that we have more than 64 unique characters to
represent. I.e. we need at least 7 bits. Since computers are more
efficient at processing bit sequences aligned a particular way, many
implementations use 8-bits for an ASCII set. 

\paragraph{For Languages with Ideographs, Require 2 Bytes}
But what about other languages? Chinese,
Japanese, and Korean have somewhere between $2^8$ and $2^{16} - 1$
unique characters, whence we
require a two-byte
sequence to store each character in these languages.
So, different languages (or regions) require different
\href{https://en.wikipedia.org/wiki/Character_encoding#Common_character_encodings}{\emph{character
    encodings}} to map symbols (text) to bit-sequences.

\paragraph{For World of All Languages, (naively) Require 4 Bytes}
But what about
the world wide web? The number of unique characters across all
languages exceeds $65,535$, whence we require strictly more than
two-bytes to encode any character coming from any language in the
world. Sticking with powers of two, we'll use four-bytes. But all of a
sudden, we realize how expensive this has become; any given language
only requires one or at most two bytes per character, but we're using
double that.

The advantage to UTF-32 (the 4-byte unicode encoding) despite it being
costly in terms of storage is that because each character is
represented as a fixed width sequence of bits, we can slice into
strings in constant time. I.e. looking up the $n$th character in a
string is easy, we simply look up where the object lives in memory and
jump $n$ characters forward in memory, where each character
corresponds to exactly 32-bits.

\paragraph{Using a Variable Length Encoding $\leadsto$ Efficiency}
Alas, we've followed Mark Pilgrim's motivation of UTF-8
\href{http://histo.ucsf.edu/BMS270/diveintopython3-r802.pdf}
{as per Chapter 4 of ``Dive Into Python''}. UTF-8 is a \emph{variable length encoding}.
The implication is that the set of ASCII characters each
requires only a single byte per character. Latin characters such as
{\"a} and {\~n} may require two bytes per character, Chinese
characters may involve three bytes, and rarely used characters require
four bytes. However, since each character requires a different
number of bits, we can \emph{no longer} jump to the $k$th character of a string with
$O(1)$ work; we're relegated to inspecting the first $k-1$ characters
to find out where in the bit-sequence the $k$th character is represented.

\paragraph{Default String Encoding in Python is UTF-8}
Default string encoding in Python 3 is
\href{https://en.wikipedia.org/wiki/UTF-8}{UTF-8}.
The change from ACSII to Unicode between Python 2 and 3 caused major
headaches for Python community.
The fact that each character of text may take from
1 to 4 bytes is nice in that the 1-byte codes
correspond to ASCII characters, which makes UTF-8 backwards
compatible with ASCII. Currently,
UTF-8 encodes a total of 1,112,064 characters, which is enough to represent
the majority of human character systems.

\subsection{Floating Point Representation of Numeric Values}
How do we represent a floating point value using bits?

\begin{figure}[h]
\centering
\includegraphics[scale=0.45]{fig/float.png}
\caption{\footnotesize A representation of a decimal value that is broken down into
  three pieces: (i) a sign bit, (ii) a fractional component, and (iii)
  an exponent indicating the magnitude of rescaling. This is a generic
  recipe for approximating real numbers using a finite set of bits.}
\end{figure}


\subsubsection{Floating Point Standard}
\href{https://en.wikipedia.org/wiki/IEEE_754}
{IEEE (Institute of Electrical and Electronics Engineers) 754} is the
technical standard for floating point used by all modern processors
The standard also specifies things like rounding modes, handling overflow,
divide by zero, etc. 

\begin{figure}[h]
\centering
\includegraphics[scale=0.4]{fig/float-table.png}
\caption{\footnotesize 32 vs. 64-bit floating point formats.
  In moving from 32-bit to 64-bit standards, IEE
  increased the number of bits allocated to the mantissa significantly
  more than they did the exponent: with 11-bits for the
  exponent, we can represent $2^{11} = 2,048$ different values of
  exponents. We center these exponents around zero using a
  \href{https://en.wikipedia.org/wiki/Exponent_bias}{exponent bias},
  such that we can store exponents in the range $\pm 2^{10}$. But
  these are exponents, i.e. they are used to raise our base to a
  specified power. That's an astronomically
  large rescaling.}
\end{figure}

\begin{figure}[h]
  \centering
  \includegraphics[scale=0.45]{fig/IEEE_754}
  \caption{\footnotesize A visual layout of the 64 bit representation used to store
    a floating point value. We have 1 sign bit, 52 mantissa
(significand, fractional) bits, and 11 exponent bits. Source: \href{https://en.wikipedia.org/wiki/Double-precision_floating-point_format}{Wikipeda}.}
\end{figure}

Symbolically, 

\begin{align*}
  (-1)^{\textrm{sgn}} \underbrace{\left(1 + \sum_{i=1}^{52} b_{52-i} 2^{-i}
  \right)}_{= \left(1.b_{51} b_{50} \ldots b_0\right)_2} \times 2^{\textrm{exp} - 1023}
\end{align*}

where the exponent term $\textrm{exp}$ is simply an integer value
represented using 11 bits in a vanilla fashion, and we're subtracting
1,023 as means of
\href{https://en.wikipedia.org/wiki/Exponent_bias}{exponent bias} such
that we can have both positive and negative exponents without
requiring the use of an \emph{additional} sign-bit for just the
exponent term.

\paragraph{Floating Point and You}
Floating point also has similar potential for overflow and underflow.
In addition, the limited number of bits for the mantissa means it
often needs to be rounded.
We'll spend more time on floating point arithmetic in CME 212.
Canonical resource: ``What Every Computer Scientist Should Know About
Floating-Point Arithmetic'' by Goldberg
(\href{https://ece.uwaterloo.ca/~dwharder/NumericalAnalysis/02Numerics/Double/paper.pdf}{link}).
Floating point numbers in Python are double precision (64-bit).
Additionally, \texttt{numpy} has support for 16-bit and 32-bit floating point formats.

\vspace{-2ex}
\subsubsection{Correctness}

{
  \small
\begin{quote}
\textbf{Some disasters attributable to bad numerical computing}

By Douglas N. Arnold.
{\footnotesize \url{http://www.math.umn.edu/~arnold/disasters/disasters.html}}

Have you been paying attention in your numerical analysis or scientific
computation courses? If not, it could be a costly mistake. Here are some
real life examples of what can happen when numerical algorithms are not
correctly applied.

The
\href{http://www-users.math.umn.edu/~arnold/disasters/patriot.html}{Patriot
  Missile failure},
in Dharan, Saudi Arabia, on February 25,
1991 which resulted in 28 deaths, is ultimately attributable to poor
handling of rounding errors.

The \href{http://www-users.math.umn.edu/~arnold/disasters/ariane.html}{explosion of the Ariane 5 rocket} just after lift-off on its maiden
voyage off French Guiana, on June 4, 1996, was ultimately the
consequence of a simple overflow.

The
\href{http://www-users.math.umn.edu/~arnold/disasters/sleipner.html}{sinking
  of the Sleipner A offshore platform}
in Gandsfjorden near
Stavanger, Norway, on August 23, 1991, resulted in a loss of nearly one
billion dollars. It was found to be the result of inaccurate finite
element analysis.
\end{quote}
}

See also: \url{https://people.eecs.berkeley.edu/~wkahan/} for thoughts
from the \href{https://en.wikipedia.org/wiki/William_Kahan}{father of
  floating point}, i.e. the primary architect of an IEEE standard for
representing floating point values in a computer architecture. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Python for Numerical Computing}
\subsection{Motivation: Python is (Relatively) Slow}
One of the main disadvantages of a higher level language is that, while
comparatively easy to program, it offers less direct control over
resources; an experienced programmer using C++ or other lower level
languages
may be able to write a more performant program.

\begin{figure}[h]
\centering
\includegraphics[scale=0.45]{fig/python-v-compiled.png}
\caption{\footnotesize The Python interpreter sits between the programmer's code and
the machine. In the case of a lower level language such as C++, the
programmer has direct control over memory management and more granular
control over data types. A knowledgeable programmer can take advantage
of the particular computer architecture they are using, alongside the
problem constraints, in order to more efficiently write code to solve
a task. This is harder with Python, wherein the code that the
programmer writes is first translated by the interpreter such that the
machine may understand it. We remark that of course C++ code also must
be translated to machine code, but that it ties in much closer to said
assembly code than Python.}
\end{figure}

\subsubsection{Runtime Performance: An Empirical Example}
Let's compute \(2^i\) for \(i \in [0,n)\). We can use the
\href{https://docs.python.org/3/library/timeit.html#basic-examples}{\texttt{timeit} module}.
Using lists, and from the command line
interface.

\begin{lstlisting}[language=bash,basicstyle=\small]
  $ python3 -m timeit --setup='L=range(1000)' '[i**2 for i in L]'
\end{lstlisting}

Equivalently, we can use the \texttt{\%timeit} magic command in an
IPython notebook.

\begin{lstlisting}[language=bash,basicstyle=\small]
  $ ipython
  In [1]: L = range(1000)
  In [2]: %timeit [i**2 for i in L]
\end{lstlisting}

What happens if we try the same operation using \texttt{numpy}? The
analogous operation to \texttt{range} in built-in Python is the
\texttt{arange} method in \texttt{numpy}. For integer arguments, the
two functions behave the same, but \texttt{numpy.arange} extends to
handling non-integer arguments.\footnote{The \texttt{range}
  sub-routine is designed to return \emph{indices} that can be used as
  subscript arguments when slicing an object, whereas the
  \texttt{numpy.arange} is a more generalized function which can take
  arbitrary boundary points and step-sizes.}

\begin{python}
  import numpy as np
  a = np.arange(1000)
  %timeit a**2
\end{python}

On my machine, the difference is about 300x.
We'll explore how \texttt{numpy} is able to achieve such
performance gains throughout the lecture. For now, let's continue to
explore how the module can not only allow our programs to execute
faster once built, but in fact \texttt{numpy} lets us write the more
concise code that is capable of a higher level of abstraction. 

\subsubsection{Programmer Productivity}
And even though Python is a high-level programming language, it's
still a general purpose one. I.e. it is not tailored to numerical or
scientific computing. Whence we \emph{do} have to write additional
code in order to abstract away commonly used operations in maths and
sciences.

E.g. let's add some 2D arrays. 
In Python, we could try and create a two-dimensional tabular data
structure using lists of lists. In order to facilitate something as
easy as ``adding'' two 2D-arrays together, we'd have to write our own
sub-routine, since the \texttt{+} operator performs
\emph{concatenation} on lists rather than element wise addition!

\begin{python}
def my_ones(nrows, ncols):
    """
    Create a matrix-like object of dimension nrows x ncols, with each
    element taking unit value.
    """
    A = []
    for r in range(nrows):
        A.append([])
        for c in range(ncols):
            A[r].append(1.0)
    return A

def matrix_add(A,B):
    """
    Create a new matrix-like object to store the result of adding
    input matrices A and B. We assume the matrices have identical
    dimension. The work required by the algorithm is proportional to
    the number of elements stored in the input matrices.
    """
    C = []
    for r in range(len(A)):
        C.append([])
        for c in range(len(A[r])):
            C[r].append(A[r][c] + B[r][c])
    return C

nrows, ncols = 3, 2
A = my_ones(nrows,ncols)
B = my_ones(nrows,ncols)
C = matrix_add(A,B)
\end{python}

What about with \texttt{numpy}? The operations are trivial to carry
out without defining our own data structures or sub-routines.
I.e. we can ``program faster''.

\begin{python}
nrows = 3
ncols = 2

A = np.ones((nrows,ncols))
B = np.ones((nrows,ncols))

C = A + B
\end{python}

Seems a lot easier to write. Let's check if we earned ourselves a performance again.
Suppose we have placed our definition of \texttt{my\_ones} into a
standalone file in our current working directory, which we call
\texttt{my\_module.py}. We may time the performance as
follows, using
\begin{lstlisting}[language=bash,basicstyle=\small]
  $ python3 -m timeit --setup='import my_module' 'my_module.my_ones(1000, 500)'
\end{lstlisting}

Alternatively, in an IPython notebook we may simply
write \texttt{\%timeit A = my\_ones(1000,500)}.
\texttt{numpy} is able to accomplish the analogous operation on my
machine approximately 200x faster. I.e. whereas the hand-rolled variant required
50 \emph{milliseconds} per loop, the \texttt{numpy} analogue below
requires only 200 \emph{microseconds} per loop.\footnote{There are 1,000
microseconds in a millisecond.}

\begin{lstlisting}[language=bash,basicstyle=\small]
  $ python3 -m timeit --setup='import numpy as np' 'np.ones((1000, 500))'
\end{lstlisting}

What about our add operation? In a IPython notebook, with \texttt{my\_ones} as per above.

\begin{python}[basicstyle=\footnotesize]
nrows = 1000
ncols = 500

A = my_ones(nrows,ncols)
B = my_ones(nrows,ncols)
%timeit C = matrix_add(A,B)

A = np.ones((nrows,ncols))
B = np.ones((nrows,ncols))
%timeit C = A + B
\end{python}

Again we see that \texttt{numpy} is orders of magnitude faster.

\paragraph{Object Overhead} The reason that 

\begin{figure}[h]
\centering
\includegraphics[scale=0.45]{fig/object-overhead.png}
\caption{fig}
\end{figure}

\subsection{Options for better performance}

Python is great for quick projects, prototyping new ideas, etc. but
what if you need better performance?
One option is to completely rewrite your program in something like
C or C++

\subsubsection{Python C API}
Python has a C API which allows the use of compiled modules

\begin{figure}[h]
\centering
\includegraphics[scale=0.45]{fig/python-c-interface.png}
\caption{fig}
\end{figure}

The actual implementation of \texttt{string.find()} can be viewed at:
\href{http://svn.python.org/view/python/trunk/Objects/stringlib/fastsearch.h}{stringlib/fastsearch.h}.

\subsubsection{Python compiled modules}

Python code in a \texttt{.py} file is actually executed in a hybrid
approach by a mix of the interpreter and compiled modules that come
with Python

\begin{figure}[h]
\centering
\includegraphics[scale=0.45]{fig/python-compiled-modules.png}
\caption{fig}
\end{figure}

\hypertarget{extension-modules}{%
\subsubsection{Extension modules}\label{extension-modules}}

\begin{itemize}
\item
  The same Python C API used by the developers of Python itself also
  allows other programmers to develop and build their own compiled
  extension modules
\item
  These modules extend the functionality of Python with high performance
  implementations of common operations
\item
  Other languages, such as C++ and Fortran, are also supported by using
  the C API
\end{itemize}

\hypertarget{numpy-scipy-matplotlib}{%
\subsubsection{NumPy, SciPy, matplotlib}\label{numpy-scipy-matplotlib}}

\begin{itemize}
\item
  NumPy - multidimensional arrays and fundamental operations on them
\item
  SciPy - Various math functionality (linear solvers, FFT, optimization,
  etc.) utilizing NumPy arrays
\item
  matplotlib - plotting and data visualization
\item
  None of these packages seek to clone MATLAB, if you want that try
  something like GNU Octave
\end{itemize}

\hypertarget{python-software-stack}{%
\subsubsection{Python software stack}\label{python-software-stack}}

\begin{figure}[h]
\centering
\includegraphics[scale=0.45]{fig/python-stack.png}
\caption{fig}
\end{figure}



\subsection{Motivation}


\hypertarget{numpy}{%
\subsection{NumPy}\label{numpy}}

NumPy provides a numeric array object:

\begin{python}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}
\NormalTok{a }\OperatorTok{=}\NormalTok{ np.array([}\DecValTok{7}\NormalTok{, }\DecValTok{42}\NormalTok{, }\DecValTok{-3}\NormalTok{])}
\BuiltInTok{print}\NormalTok{(a)}
\end{Highlighting}
\end{python}

\begin{python}
\begin{Highlighting}[]
\NormalTok{a[}\DecValTok{1}\NormalTok{]}
\end{Highlighting}
\end{python}

\begin{python}
\begin{Highlighting}[]
\NormalTok{a[}\DecValTok{1}\NormalTok{] }\OperatorTok{=} \DecValTok{19}
\NormalTok{a}
\end{Highlighting}
\end{python}

\hypertarget{arrays-are-not-lists}{%
\subsubsection{Arrays are not lists}\label{arrays-are-not-lists}}

\begin{python}
\begin{Highlighting}[]
\NormalTok{a[}\DecValTok{0}\NormalTok{] }\OperatorTok{=} \StringTok{"hello"}
\end{Highlighting}
\end{python}

\begin{python}
\begin{Highlighting}[]
\NormalTok{a.append(}\DecValTok{8}\NormalTok{)}
\end{Highlighting}
\end{python}

\hypertarget{numpy-arrays}{%
\subsubsection{NumPy arrays}\label{numpy-arrays}}

\begin{itemize}
\item
  NumPy arrays contain \textbf{homogeneous} data (all elements must have
  same type)
\item
  Size is fixed, i.e.~you can't append or remove
\end{itemize}

\hypertarget{data-types}{%
\subsubsection{Data types}\label{data-types}}

\begin{itemize}
\item
  Integers

  \begin{itemize}
  
  \item
    8, 16, 32, and 64 bit signed and unsigned (np.int8, np.uint8, etc.)
  \end{itemize}
\item
  Floating point

  \begin{itemize}
  
  \item
    32, 64, 128 bit (np.float32, np.float64, etc.)
  \end{itemize}
\item
  Complex, strings, and Python object references also supported
\end{itemize}

\hypertarget{data-type-examples}{%
\subsubsection{Data type examples}\label{data-type-examples}}

\begin{python}
\begin{Highlighting}[]
\NormalTok{a }\OperatorTok{=}\NormalTok{ np.array([ }\DecValTok{7}\NormalTok{, }\DecValTok{19}\NormalTok{, }\DecValTok{-3}\NormalTok{], dtype}\OperatorTok{=}\NormalTok{np.float32)}
\NormalTok{a}
\end{Highlighting}
\end{python}

\begin{python}
\begin{Highlighting}[]
\NormalTok{a[}\DecValTok{0}\NormalTok{] }\OperatorTok{=}\NormalTok{ a[}\DecValTok{0}\NormalTok{]}\OperatorTok{/}\FloatTok{0.}
\NormalTok{a}
\end{Highlighting}
\end{python}

\begin{python}
\begin{Highlighting}[]
\NormalTok{b }\OperatorTok{=}\NormalTok{ np.array([}\DecValTok{4}\NormalTok{, }\DecValTok{7}\NormalTok{, }\DecValTok{19}\NormalTok{], dtype}\OperatorTok{=}\NormalTok{np.int8)}
\NormalTok{b}
\end{Highlighting}
\end{python}

\begin{python}
\begin{Highlighting}[]
\NormalTok{b[}\DecValTok{0}\NormalTok{] }\OperatorTok{=} \DecValTok{437}
\NormalTok{b}
\end{Highlighting}
\end{python}

\hypertarget{multidimensional-arrays}{%
\subsubsection{Multidimensional arrays}\label{multidimensional-arrays}}

\begin{itemize}
\item
  Arrays can have multiple dimensions called \emph{axes}
\item
  The number of \emph{axes} is called the \emph{rank}
\item
  These terms come from the NumPy community and should not be confused
  with linear algebra terms for \emph{rank}, etc.
\end{itemize}

\hypertarget{multidimensional-arrays-1}{%
\subsubsection{Multidimensional
arrays}\label{multidimensional-arrays-1}}

\begin{python}
\begin{Highlighting}[]
\NormalTok{a }\OperatorTok{=}\NormalTok{ np.array([(}\DecValTok{7}\NormalTok{, }\DecValTok{19}\NormalTok{, }\DecValTok{-3}\NormalTok{), (}\DecValTok{4}\NormalTok{, }\DecValTok{8}\NormalTok{, }\DecValTok{17}\NormalTok{)], dtype}\OperatorTok{=}\NormalTok{np.float64)}
\NormalTok{a}
\end{Highlighting}
\end{python}

\begin{python}
\begin{Highlighting}[]
\NormalTok{a.ndim}
\end{Highlighting}
\end{python}

\begin{python}
\begin{Highlighting}[]
\NormalTok{a.dtype}
\end{Highlighting}
\end{python}

\begin{python}
\begin{Highlighting}[]
\NormalTok{a.shape}
\end{Highlighting}
\end{python}

\begin{python}
\begin{Highlighting}[]
\NormalTok{a.size}
\end{Highlighting}
\end{python}

\hypertarget{internal-representation}{%
\subsubsection{Internal representation}\label{internal-representation}}

\begin{figure}[h]
\centering
\includegraphics[scale=0.45]{fig/numpy-representation.png}
\caption{fig}
\end{figure}

\hypertarget{creating-arrays}{%
\subsubsection{Creating arrays}\label{creating-arrays}}

\begin{python}
\begin{Highlighting}[]
\NormalTok{a }\OperatorTok{=}\NormalTok{ np.empty((}\DecValTok{3}\NormalTok{,}\DecValTok{3}\NormalTok{))}
\NormalTok{a}
\end{Highlighting}
\end{python}

\begin{python}
\begin{Highlighting}[]
\NormalTok{a }\OperatorTok{=}\NormalTok{ np.zeros((}\DecValTok{3}\NormalTok{,}\DecValTok{3}\NormalTok{))}
\NormalTok{a}
\end{Highlighting}
\end{python}

\begin{python}
\begin{Highlighting}[]
\NormalTok{a }\OperatorTok{=}\NormalTok{ np.ones((}\DecValTok{3}\NormalTok{,}\DecValTok{3}\NormalTok{))}
\NormalTok{a}
\end{Highlighting}
\end{python}

\begin{python}
\begin{Highlighting}[]
\NormalTok{a }\OperatorTok{=}\NormalTok{ np.eye(}\DecValTok{3}\NormalTok{)}
\NormalTok{a}
\end{Highlighting}
\end{python}

\begin{python}
\begin{Highlighting}[]
\NormalTok{a }\OperatorTok{=}\NormalTok{ np.arange(}\DecValTok{9}\NormalTok{, dtype}\OperatorTok{=}\NormalTok{np.float64)}
\NormalTok{a}
\end{Highlighting}
\end{python}

\begin{python}
\begin{Highlighting}[]
\NormalTok{a }\OperatorTok{=}\NormalTok{ np.arange(}\DecValTok{9}\NormalTok{, dtype}\OperatorTok{=}\NormalTok{np.float64).reshape(}\DecValTok{3}\NormalTok{,}\DecValTok{3}\NormalTok{)}
\NormalTok{a}
\end{Highlighting}
\end{python}

\hypertarget{reading-data-from-a-file}{%
\subsubsection{Reading data from a
file}\label{reading-data-from-a-file}}

\begin{python}
\begin{Highlighting}[]
\NormalTok{$ }\FunctionTok{cat}\NormalTok{ numbers.txt}
\ExtensionTok{7.}\NormalTok{ 19. -3.}
\ExtensionTok{4.}\NormalTok{ 8. 17.}
\end{Highlighting}
\end{python}

\begin{python}
\begin{Highlighting}[]
\NormalTok{a }\OperatorTok{=}\NormalTok{ np.loadtxt(}\StringTok{'numbers.txt'}\NormalTok{, dtype}\OperatorTok{=}\NormalTok{np.float64)}
\NormalTok{a}
\end{Highlighting}
\end{python}

\begin{python}
\begin{Highlighting}[]
\NormalTok{a }\OperatorTok{=}\NormalTok{ a }\OperatorTok{+} \DecValTok{1}
\NormalTok{np.savetxt(}\StringTok{'numbers2.txt'}\NormalTok{, a)}
\end{Highlighting}
\end{python}

\hypertarget{remove-single-dimension-entry}{%
\subsubsection{Remove single dimension
entry}\label{remove-single-dimension-entry}}

\begin{python}
\begin{Highlighting}[]
\NormalTok{a }\OperatorTok{=}\NormalTok{ np.arange(}\DecValTok{3}\NormalTok{)}
\NormalTok{a}
\end{Highlighting}
\end{python}

\begin{python}
\begin{Highlighting}[]
\NormalTok{a.shape}
\NormalTok{b }\OperatorTok{=}\NormalTok{ np.arange(}\DecValTok{3}\NormalTok{).reshape(}\DecValTok{3}\NormalTok{,}\DecValTok{1}\NormalTok{)}
\BuiltInTok{print}\NormalTok{(b)}
\BuiltInTok{print}\NormalTok{(b.shape)}
\NormalTok{b }\OperatorTok{=}\NormalTok{ np.squeeze(b)}
\BuiltInTok{print}\NormalTok{(b)}
\BuiltInTok{print}\NormalTok{(b.shape)}
\end{Highlighting}
\end{python}

\hypertarget{array-operations}{%
\subsubsection{Array operations}\label{array-operations}}

\begin{python}
\begin{Highlighting}[]
\NormalTok{a }\OperatorTok{=}\NormalTok{ np.arange(}\DecValTok{9}\NormalTok{, dtype}\OperatorTok{=}\NormalTok{np.float64)}
\NormalTok{a}
\end{Highlighting}
\end{python}

\begin{python}
\begin{Highlighting}[]
\CommentTok{# a slice}
\NormalTok{a[}\DecValTok{3}\NormalTok{:}\DecValTok{7}\NormalTok{]}
\end{Highlighting}
\end{python}

\begin{python}
\begin{Highlighting}[]
\CommentTok{# assign to a slice}
\NormalTok{a[}\DecValTok{3}\NormalTok{:}\DecValTok{7}\NormalTok{] }\OperatorTok{=} \DecValTok{0}
\NormalTok{a}
\end{Highlighting}
\end{python}

\begin{python}
\begin{Highlighting}[]
\DecValTok{2}\OperatorTok{*}\NormalTok{a}
\end{Highlighting}
\end{python}

\begin{python}
\begin{Highlighting}[]
\NormalTok{a}\OperatorTok{*}\NormalTok{a}
\end{Highlighting}
\end{python}

\begin{python}
\begin{Highlighting}[]
\BuiltInTok{sum}\NormalTok{(a)}
\end{Highlighting}
\end{python}

\begin{python}
\begin{Highlighting}[]
\BuiltInTok{min}\NormalTok{(a)}
\end{Highlighting}
\end{python}

\begin{python}
\begin{Highlighting}[]
\BuiltInTok{max}\NormalTok{(a)}
\end{Highlighting}
\end{python}

\hypertarget{array-operations-1}{%
\subsubsection{Array operations}\label{array-operations-1}}

\begin{python}
\begin{Highlighting}[]
\NormalTok{a }\OperatorTok{=}\NormalTok{ np.arange(}\DecValTok{9}\NormalTok{, dtype}\OperatorTok{=}\NormalTok{np.float64)}
\BuiltInTok{print}\NormalTok{(a)}

\CommentTok{# bad idea}
\NormalTok{total }\OperatorTok{=} \FloatTok{0.}
\ControlFlowTok{for}\NormalTok{ n }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(}\BuiltInTok{len}\NormalTok{(a)):}
\NormalTok{    total }\OperatorTok{+=}\NormalTok{ a[n]}\OperatorTok{*}\NormalTok{a[n]}

\NormalTok{math.sqrt(total)}
\end{Highlighting}
\end{python}

\begin{python}
\begin{Highlighting}[]
\CommentTok{# better idea}
\ImportTok{import}\NormalTok{ math}
\NormalTok{math.sqrt(np.dot(a,a))}
\end{Highlighting}
\end{python}

\begin{python}
\begin{Highlighting}[]
\CommentTok{# best idea}
\NormalTok{np.linalg.norm(a)}
\end{Highlighting}
\end{python}

\hypertarget{speed-of-array-operations}{%
\subsubsection{Speed of array
operations}\label{speed-of-array-operations}}

\begin{python}
\begin{Highlighting}[]
\OperatorTok{%}\NormalTok{timeit total }\OperatorTok{=} \BuiltInTok{sum}\NormalTok{(np.ones(}\DecValTok{1000000}\NormalTok{,dtype}\OperatorTok{=}\NormalTok{np.int32))}
\end{Highlighting}
\end{python}

\begin{python}
\begin{Highlighting}[]
\OperatorTok{%}\NormalTok{timeit total }\OperatorTok{=}\NormalTok{ np.}\BuiltInTok{sum}\NormalTok{(np.ones(}\DecValTok{1000000}\NormalTok{,dtype}\OperatorTok{=}\NormalTok{np.int32))}
\end{Highlighting}
\end{python}

\hypertarget{loops-vs.array-operations}{%
\subsubsection{Loops vs.~array
operations}\label{loops-vs.array-operations}}

\begin{itemize}
\item
  Loops you write in Python will be executed by the interpreter
\item
  Some of the overloaded operators (e.g. \texttt{min}, \texttt{max},
  \texttt{sum}, etc.) work albeit slowly
\item
  Calling NumPy function or methods of the array object will invoke high
  performance implementations of these operations
\end{itemize}

\hypertarget{matrix-operations}{%
\subsubsection{Matrix operations}\label{matrix-operations}}

\begin{python}
\begin{Highlighting}[]
\NormalTok{a }\OperatorTok{=}\NormalTok{ np.arange(}\DecValTok{9}\NormalTok{, dtype}\OperatorTok{=}\NormalTok{np.float64).reshape(}\DecValTok{3}\NormalTok{,}\DecValTok{3}\NormalTok{)}
\NormalTok{a}
\end{Highlighting}
\end{python}

\begin{python}
\begin{Highlighting}[]
\NormalTok{a.transpose()}
\end{Highlighting}
\end{python}

\begin{python}
\begin{Highlighting}[]
\NormalTok{np.trace(a)}
\end{Highlighting}
\end{python}

\begin{python}
\begin{Highlighting}[]
\NormalTok{a}\OperatorTok{*}\NormalTok{a }\CommentTok{# element wise multiplication}
\end{Highlighting}
\end{python}

\begin{python}
\begin{Highlighting}[]
\NormalTok{np.dot(a,a) }\CommentTok{# matrix-matrix multiplication}
\end{Highlighting}
\end{python}

\begin{python}
\begin{Highlighting}[]
\CommentTok{# new matrix multiply operator in Python 3.5}
\NormalTok{a }\OperatorTok{@}\NormalTok{ a}
\end{Highlighting}
\end{python}

\hypertarget{array-vs-matrix}{%
\subsubsection{array vs matrix}\label{array-vs-matrix}}

\begin{itemize}
\item
  NumPy has a dedicated matrix class
\item
  However, the matrix class is not as widely used and there are subtle
  differences between a 2D array and a matrix
\item
  It is highly recommended that you use 2D arrays for maximum
  compatibility with other NumPy functions, SciPy, matplotlib, etc.
\item
  See here for more details:
\end{itemize}

\url{http://www.scipy.org/NumPy_for_Matlab_Users}

(\texttt{array\textquotesingle{}\ or}matrix'? Which should I use?)

\hypertarget{references-to-an-array}{%
\subsubsection{References to an array}\label{references-to-an-array}}

\begin{python}
\begin{Highlighting}[]
\NormalTok{a }\OperatorTok{=}\NormalTok{ np.arange(}\DecValTok{9}\NormalTok{, dtype}\OperatorTok{=}\NormalTok{np.float64).reshape(}\DecValTok{3}\NormalTok{,}\DecValTok{3}\NormalTok{)}
\NormalTok{a}
\end{Highlighting}
\end{python}

\begin{python}
\begin{Highlighting}[]
\NormalTok{b }\OperatorTok{=}\NormalTok{ a}
\NormalTok{b[}\DecValTok{0}\NormalTok{,}\DecValTok{0}\NormalTok{] }\OperatorTok{=} \DecValTok{42}
\NormalTok{b}
\end{Highlighting}
\end{python}

\begin{python}
\begin{Highlighting}[]
\NormalTok{a}
\end{Highlighting}
\end{python}

\hypertarget{array-slices-and-references}{%
\subsubsection{Array slices and
references}\label{array-slices-and-references}}

\begin{python}
\begin{Highlighting}[]
\NormalTok{a }\OperatorTok{=}\NormalTok{ np.arange(}\DecValTok{9}\NormalTok{, dtype}\OperatorTok{=}\NormalTok{np.float64)}
\NormalTok{a}
\end{Highlighting}
\end{python}

\begin{python}
\begin{Highlighting}[]
\NormalTok{b }\OperatorTok{=}\NormalTok{ a[}\DecValTok{2}\NormalTok{:}\DecValTok{7}\NormalTok{]}
\NormalTok{b}
\end{Highlighting}
\end{python}

\begin{python}
\begin{Highlighting}[]
\NormalTok{b[}\DecValTok{2}\NormalTok{] }\OperatorTok{=} \DecValTok{-1}
\NormalTok{b}
\end{Highlighting}
\end{python}

\begin{python}
\begin{Highlighting}[]
\NormalTok{a}
\end{Highlighting}
\end{python}

\hypertarget{array-copies}{%
\subsubsection{Array copies}\label{array-copies}}

\begin{python}
\begin{Highlighting}[]
\NormalTok{a }\OperatorTok{=}\NormalTok{ np.arange(}\DecValTok{9}\NormalTok{, dtype}\OperatorTok{=}\NormalTok{np.float64)}
\NormalTok{a}
\end{Highlighting}
\end{python}

\begin{python}
\begin{Highlighting}[]
\NormalTok{b }\OperatorTok{=}\NormalTok{ a.copy()}
\NormalTok{b}
\end{Highlighting}
\end{python}

\begin{python}
\begin{Highlighting}[]
\NormalTok{b[}\DecValTok{4}\NormalTok{] }\OperatorTok{=} \DecValTok{-1}
\NormalTok{b}
\end{Highlighting}
\end{python}

\begin{python}
\begin{Highlighting}[]
\NormalTok{a}
\end{Highlighting}
\end{python}

\hypertarget{universal-functions-ufuncs}{%
\subsubsection{Universal functions
(ufuncs)}\label{universal-functions-ufuncs}}

\begin{python}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ numpy}
\NormalTok{a }\OperatorTok{=}\NormalTok{ np.arange(}\DecValTok{9}\NormalTok{, dtype}\OperatorTok{=}\NormalTok{np.float64)}
\NormalTok{a}
\end{Highlighting}
\end{python}

\begin{python}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ math}
\NormalTok{math.sqrt(a)}
\end{Highlighting}
\end{python}

\begin{python}
\begin{Highlighting}[]
\NormalTok{np.sqrt(a)}
\end{Highlighting}
\end{python}

\hypertarget{beyond-just-arrays}{%
\subsubsection{Beyond just arrays}\label{beyond-just-arrays}}

\begin{itemize}
\item
  NumPy has some support for some useful operations beyond the usual
  vector and matrix operations:

  \begin{itemize}
  \item
    Searching, sorting, and counting within arrays
  \item
    FFT (Fast Fourier Transform)
  \item
    Linear Algebra
  \item
    Statistics
  \item
    Polynomials
  \item
    Random number generation
  \end{itemize}
\item
  SciPy has largely replaced much of this functionality, plus added much
  more
\end{itemize}

\hypertarget{warning}{%
\subsubsection{Warning}\label{warning}}

\begin{itemize}
\item
  Once you start making use of extension modules such as NumPy, SciPy,
  etc. the chances of code ``breaking'' when you run it on different
  machines goes up significantly
\item
  If you do some of your development on machines other than corn (which
  isn't the model we advise) you may run into issues
\end{itemize}

\hypertarget{further-reading}{%
\subsubsection{Further Reading}\label{further-reading}}

\begin{itemize}

\item
  MATLAB users: \url{http://www.scipy.org/NumPy_for_Matlab_Users}
\item
  NumPy tutorial at: \url{http://www.scipy.org/Tentative_NumPy_Tutorial}
\item
  Official docs at: \url{http://docs.scipy.org/}
\end{itemize}

\end{document}
